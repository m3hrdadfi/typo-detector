<h1 align="center">Typo Detector using Transformers ğŸ¦</h1>
<br/>


## English Version

### Dataset Information

For this specific task, I used [NeuSpell](https://github.com/neuspell/neuspell) dataset as my raw-data.

### Evaluation

The following tables summarize the scores obtained by model overall and per each class.

|       #      | precision |  recall  | f1-score |  support |
|:------------:|:---------:|:--------:|:--------:|:--------:|
|     TYPO     |  0.992332 | 0.985997 | 0.989154 | 416054.0 |
|   micro avg  |  0.992332 | 0.985997 | 0.989154 | 416054.0 |
|   macro avg  |  0.992332 | 0.985997 | 0.989154 | 416054.0 |
| weighted avg |  0.992332 | 0.985997 | 0.989154 | 416054.0 |


## Icelandic Version

### Dataset Information
Synthetic data for this specific task.


### Evaluation

The following tables summarize the scores obtained by model overall and per each class.

|       #      | precision |  recall  | f1-score | support |
|:------------:|:---------:|:--------:|:--------:|:-------:|
|     TYPO     |  0.98954  | 0.967603 | 0.978448 | 43800.0 |
|   micro avg  |  0.98954  | 0.967603 | 0.978448 | 43800.0 |
|   macro avg  |  0.98954  | 0.967603 | 0.978448 | 43800.0 |
| weighted avg |  0.98954  | 0.967603 | 0.978448 | 43800.0 |


## Persian Version

<div dir="rtl">
ØªØ´Ø®ÛŒØµâ€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø®Ø·Ø§â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù„Ø§ÛŒÛŒØŒ Ø­Ø§ØµÙ„ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨ÛŒØ´ Ø§Ø² Û±Û°Û° Ø³Ø§Ø¹Øª Ø¨Ø± Ø±ÙˆÛŒ Ø¨ÛŒØ´ Ø§Ø² Û² Ù…ÛŒÙ„ÛŒÙˆÙ† Ø¯ÛŒØªØ§ Ø§Ø³Øª. Ø§ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ Ùˆ Ù…Ù‚Ø§Ù„Ø§Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø¢Ø²Ø§Ø¯ Ø¯Ø± Ø§Ø®ØªÛŒØ§Ø± Ù…Ø­Ù‚Ù‚ÛŒÙ† Ù‚Ø±Ø§Ø± Ø®ÙˆØ§Ù‡Ø¯ Ú¯Ø±ÙØª Ù‡Ù…Ú†Ù†ÛŒÙ† Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª Ø¢Ø²Ø§Ø¯ Ø¯Ø± Ù‡Ø§Ú¯ÛŒÙ†Ú¯â€ŒÙÛŒØ³ Ù‚Ø§Ø¨Ù„ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯. ÙˆÙ„ÛŒ Ù„Ø§Ø²Ù… Ø¨Ù‡ Ø°Ú©Ø± Ø§Ø³Øª Ú©Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ù…ØµØ§Ø±Ù Ø´Ø®ØµÛŒØŒ Ø§Ø³ØªØ§Ø±ØªØ§Ù¾ÛŒØŒ Ø´Ø±Ú©ØªÛŒ Ùˆ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ Ùˆ Ø­ØªÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø¯Ù„ Ùˆ ÙØ±ÙˆØ´ Ø¢Ù† Ù…Ù†Ø·Ù‚Ø§ Ùˆ Ø­Ù‚ÛŒÙ‚ØªØ§ Ø¬Ø§ÛŒØ² Ù†ÛŒØ³Øª ÙˆÙ„ÛŒ Ø´Ù…Ø§ Ù…ÛŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø®ØµÛŒ Ùˆ ÛŒØ§ Ø§Ø¨Ø¹Ø§Ø¯ Ù…Ø¯Ù„ Ú©Ø³Ø¨ Ùˆ Ú©Ø§Ø± Ø®ÙˆØ¯ØªØ§Ù† Ù„Ø§ÛŒØ³Ù†Ø³ Ø§ÛŒÙ† Ù…Ø¯Ù„ Ø±Ø§ Ø®Ø±ÛŒØ¯Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯. Ø§ÛŒÙ† Ù„Ø§ÛŒØ³Ù†Ø³ Ø´Ø§Ù…Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ØŒ ØªÙˆÙ†ÛŒÙ†Ú¯ Ù…Ø¯Ù„ Ùˆ Ø¯ÛŒÙ¾Ù„ÙˆÛŒ Ù…Ø¯Ù„ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.

- [Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø®ØµÛŒ](https://zarinp.al/377906)
- [Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¬Ù‡Øª Ø§Ø³ØªØ§Ø±ØªØ§Ù¾â€ŒÙ‡Ø§](https://zarinp.al/377907)
- [Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¬Ù‡Øª Ø´Ø±Ú©Øªâ€ŒÙ‡Ø§ Ùˆ Ø³Ø§Ø²Ù…Ø§Ù†â€ŒÙ‡Ø§](https://zarinp.al/377908)
 
Ù¾Ø³ Ø§Ø² Ø®Ø±ÛŒØ¯Ø§Ø±ÛŒ Ù„Ø§ÛŒØ³Ù†Ø³ Ø¨Ø± Ø­Ø³Ø¨ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù‡ Ø¨Ø§ Ø´Ù…Ø§ ØªÙ…Ø§Ø³ Ø®ÙˆØ§Ù‡ÛŒÙ… Ú¯Ø±ÙØªØŒ Ø¬Ù‡Øª ØªÙ†Ø¸ÛŒÙ… ÙˆÙ‚Øª Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¬Ù‡Øª Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒ Ù…Ø¯Ù„ Ù…ØªÙ†Ø§Ø³Ø¨ Ø¨Ø§ Ù†ÙˆØ¹ Ú©Ø³Ø¨â€ŒÙˆâ€ŒÚ©Ø§Ø± Ø´Ù…Ø§.
 
 **Ù„Ø§Ø²Ù… Ø¨Ù‡ Ø°Ú©Ø± Ø§Ø³Øª Ø¨Ù‡Ø¨ÙˆØ¯ Ùˆ Ø§Ø±ØªÙ‚Ø§ Ù…Ø¯Ù„ Ø¬Ø² Ø¯Ø± Ù…ÙˆØ§Ø±Ø¯ Ø®Ø±ÛŒØ¯Ø§Ø±ÛŒ Ø´Ø¯Ù‡ Ù„Ø§ÛŒØ³Ù†Ø³ (Ø´Ø®ØµÛŒØŒ Ø§Ø³ØªØ§Ø±ØªØ§Ù¾ÛŒØŒ Ø´Ø±Ú©ØªÛŒ Ùˆ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ) Ùˆ Ù…ØªÙ†Ø§Ø³Ø¨ Ø¨Ø§ Ù‡Ù…Ø§Ù† Ø²Ù…ÛŒÙ†Ù‡ Ù…Ø¬Ø§Ø² Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯. Ø´Ù…Ø§ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø§Ø¯Ù‡ Ùˆ Ø§Ø² Ø¢Ù† Ø¨Ù‡ Ù‡Ø± Ø·Ø±ÛŒÙ‚ÛŒ Ø¯Ø±Ø¢Ù…Ø¯Ø²Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯.**
 
</div>

## Dataset Information

I made synthetic data for this specific task.


## Evaluation

The following tables summarize the scores obtained by model overall and per each class.

|       #      | precision |  recall  | f1-score |  support |
|:------------:|:---------:|:--------:|:--------:|:--------:|
|     TYPO     |  0.984098 | 0.984047 | 0.984073 | 307088.0 |
|   micro avg  |  0.984098 | 0.984047 | 0.984073 | 307088.0 |
|   macro avg  |  0.984098 | 0.984047 | 0.984073 | 307088.0 |
| weighted avg |  0.984098 | 0.984047 | 0.984073 | 307088.0 |



## How to use

You use this model with Transformers pipeline for NER (token-classification).

### Installing requirements

```bash
pip install transformers
```

### Prediction using pipeline

```python
import torch
from transformers import AutoConfig, AutoTokenizer, AutoModelForTokenClassification
from transformers import pipeline


model_name_or_path = "m3hrdadfi/typo-detector-distilbert-en"
# model_name_or_path = "m3hrdadfi/typo-detector-distilbert-fa"
config = AutoConfig.from_pretrained(model_name_or_path)
tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)
model = AutoModelForTokenClassification.from_pretrained(model_name_or_path, config=config)
nlp = pipeline('token-classification', model=model, tokenizer=tokenizer, aggregation_strategy="average")
```

**For English:**
```python
sentences = [
 "He had also stgruggled with addiction during his time in Congress .",
 "The review thoroughla assessed all aspects of JLENS SuR and CPG esign maturit and confidence .",
 "Letterma also apologized two his staff for the satyation .",
 "Vincent Jay had earlier won France 's first gold in gthe 10km biathlon sprint .",
 "It is left to the directors to figure out hpw to bring the stry across to tye audience .",
]

for sentence in sentences:
    typos = [sentence[r["start"]: r["end"]] for r in nlp(sentence)]

    detected = sentence
    for typo in typos:
        detected = detected.replace(typo, f'<i>{typo}</i>')

    print("   [Input]: ", sentence)
    print("[Detected]: ", detected)
    print("-" * 130)
```

Output:
```text
   [Input]:  He had also stgruggled with addiction during his time in Congress .
[Detected]:  He had also <i>stgruggled</i> with addiction during his time in Congress .
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  The review thoroughla assessed all aspects of JLENS SuR and CPG esign maturit and confidence .
[Detected]:  The review <i>thoroughla</i> assessed all aspects of JLENS SuR and CPG <i>esign</i> <i>maturit</i> and confidence .
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  Letterma also apologized two his staff for the satyation .
[Detected]:  <i>Letterma</i> also apologized <i>two</i> his staff for the <i>satyation</i> .
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  Vincent Jay had earlier won France 's first gold in gthe 10km biathlon sprint .
[Detected]:  Vincent Jay had earlier won France 's first gold in <i>gthe</i> 10km biathlon sprint .
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  It is left to the directors to figure out hpw to bring the stry across to tye audience .
[Detected]:  It is left to the directors to figure out <i>hpw</i> to bring the <i>stry</i> across to <i>tye</i> audience .
----------------------------------------------------------------------------------------------------------------------------------
```

**For Icelandic:**
```python
sentences = [
"PÃ¡li, vini mÃ­num, langaÃ°i aÃ° horfa Ã¡ sjÃ³nnvarpiÃ°.",
"Leggir Ã¾ciÃ°ursins eru Ã¾aktir fjÃ¶Ã°rum til baÃ° edravn fuglnn gekgn kuldanuÃ© .",
"Ãar hitta Ã¾eir konu BjÃ¶rns og segir ovs :",
"Ingvar SÃ¦mundsson ekgk rÃº sveitinni Ã¡riÃ° 2015 og etnbeitii sÃ©r aÃ° hinni Ã¾ungarokkssvedt svnni Momentum .",
"Ãar hitta Ã¾eir konu BjÃ¶rns og segir ovs :",
"Var hann sÃ­Ã°aÃºn hkluti af leikhÃ³pnum sem ferÃ°aÃ°ist um BandarÃ­kin til aÃ° sÃ½an sÃ¶ngleikinn ."
]

for sentence in sentences:
    typos = [sentence[r["start"]: r["end"]] for r in nlp(sentence)]

    detected = sentence
    for typo in typos:
        detected = detected.replace(typo, f'<i>{typo}</i>')

    print("   [Input]: ", sentence)
    print("[Detected]: ", detected)
    print("-" * 130)
```

Output:
```text
   [Input]:  PÃ¡li, vini mÃ­num, langaÃ°i aÃ° horfa Ã¡ sjÃ³nnvarpiÃ°.
[Detected]:  PÃ¡li, vini mÃ­num, langaÃ°i aÃ° horfa Ã¡ <i>sjÃ³nnvarpiÃ°</i>.
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  Leggir Ã¾ciÃ°ursins eru Ã¾aktir fjÃ¶Ã°rum til baÃ° edravn fuglnn gekgn kuldanuÃ© .
[Detected]:  Leggir <i>Ã¾ciÃ°ursins</i> eru Ã¾aktir fjÃ¶Ã°rum til <i>baÃ°</i> <i>edravn</i> <i>fuglnn</i> <i>gekgn</i> <i>kuldanuÃ©</i> .
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  Ãar hitta Ã¾eir konu BjÃ¶rns og segir ovs :
[Detected]:  Ãar hitta Ã¾eir konu BjÃ¶rns og segir <i>ovs</i> :
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  Ingvar SÃ¦mundsson ekgk rÃº sveitinni Ã¡riÃ° 2015 og etnbeitii sÃ©r aÃ° hinni Ã¾ungarokkssvedt svnni Momentum .
[Detected]:  Ingvar SÃ¦mundsson <i>ekgk</i> <i>rÃº</i> sveitinni Ã¡riÃ° 2015 og <i>etnbeitii</i> sÃ©r aÃ° hinni <i>Ã¾ungarokkssvedt</i> <i>svnni</i> Momentum .
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  Ãar hitta Ã¾eir konu BjÃ¶rns og segir ovs :
[Detected]:  Ãar hitta Ã¾eir konu BjÃ¶rns og segir <i>ovs</i> :
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  Var hann sÃ­Ã°aÃºn hkluti af leikhÃ³pnum sem ferÃ°aÃ°ist um BandarÃ­kin til aÃ° sÃ½an sÃ¶ngleikinn .
[Detected]:  Var hann <i>sÃ­Ã°aÃºn</i> <i>hkluti</i> af leikhÃ³pnum sem ferÃ°aÃ°ist um BandarÃ­kin til aÃ° <i>sÃ½an</i> sÃ¶ngleikinn .
----------------------------------------------------------------------------------------------------------------------------------
```

**For Persian:**
```python
sentences = [
    'Ùˆ Ú¯Ù„ÙˆÙ„Ù‡ Ø¯ÙˆØ± Ù…Ù‚Ø§Ø¨Ú©Ù„ ØºÙ„Ù… " Ø¨ÙˆØ¯ .',
    'Ø´Ù„Ø§Ù… ØªØ§Ø±ÛŒÚ©ÛŒØŒ Ø¯ÙˆØ³ØªÙ‡ Ù‚Ø¯ÛŒÙ…ÛŒ Ù…Ù†',
    'Ø¯Ø± Ø³Ø¯Ø§ÛŒ Ø³Ú©ÙˆØªØŒ Ø¯Ø± Ø±ÙˆØ§ÛŒØ¦ Ù†Ø§Ø¢Ø±Ø§Ù… ØªÙ†Ù‡Ø§ ØºØ¯Ù… Ù…ÛŒâ€ŒØ²Ù†Ù…',
    'Ø²ÛŒØ± Ù‡Ù„Ù‚Ù‡ Ù†ÙˆØ± Ú†Ø±Ø§Øº Ø®ÛŒØ§Ø¨Ø§Ù†',
    'Ùˆ Ø¯Ø± ØµØ¯Ø§ÛŒ Ø³Ú©ÙˆØª Ø¶Ù…Ø¶Ù…Ù‡ Ù…ÛŒ Ø´ÙˆØ¯',
    'ÙˆÛŒØ±Ø§ÛŒØ³ØªÛŒØ§Ø± Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù† ØŒ Ø±ÙˆØ²Ù†Ø§Ù…Ù‡ Ù†Ú¯Ø§Ø±Ø§Ù† Ùˆ Ø§Ø³Ø­Ø§Ø¨ Ø±ØµØ§Ù†Ù‡Ù‡',
    'Ø¬Ú©ÛŒÙ… Ø§Ø¨ÙˆØ§Ù„Ù‚ÙØ§Ø³Ù… ÙØ±Ø°Ø¯ÙˆØ³ÛŒ Ø³Ø§Ø¹Ø± Ø­Ù…Ø§ØµÛŒ Ø³ØµØ±Ø§ÛŒ ØºØ±Ù† Ø¬Ù‡Ø§Ø±Ù… Ø§Ø³ØªØª ( ØªÙ…Ø§Ù…Ù…Ø§ Ù‚Ù„Ø· )',
    'Ù…ÛŒØ§Ù† Ø¹Ø§Ø´Ù‚ Ùˆ Ù…Ø¹Ø´ÙˆÙ‚ Ù‡ÛŒÚ† Ù‡Ø§Ø¦Ù„ Ù†ÛŒØ³Øª',
    'Ø¹Ø°Ø§Ù‡Ø§ÛŒ Ø²ÙˆØ¯ Ø­Ø²Ù… Ø¨Ø±Ø§ÛŒ Ù…Ø¹Ø¯Ù‡ Ø¨Ù‡ØªØ± Ø§Ø³Øª .',
    'ØºØ¶Ø§ Ø®ÙˆØ±Ø¯Ù… Ùˆ Ø±ÙØªÙ… .',
    'Ø§Ùˆ Ø´Ø§Ú¯Ø±Ø¯ Ø®Ø§Øµ Ùˆ Ø¹Ù‚Ø±Ø¨ Ø¨Ù‡ Ø§Ø³ØªØ§Ø¯ Ø¨ÙˆØ¯ .'
]

for sentence in sentences:
    typos = [sentence[r["start"]: r["end"]] for r in nlp(sentence)]

    detected = sentence
    for typo in typos:
        detected = detected.replace(typo, f' Ù€ {typo} Ù€ ')

    print("   [Input]: ", sentence)
    print("[Detected]: ", detected)
    print("-" * 130)
```

Output:
```text
   [Input]:  Ùˆ Ú¯Ù„ÙˆÙ„Ù‡ Ø¯ÙˆØ± Ù…Ù‚Ø§Ø¨Ú©Ù„ ØºÙ„Ù… " Ø¨ÙˆØ¯ .
[Detected]:  Ùˆ Ú¯Ù„ÙˆÙ„Ù‡  Ù€ Ø¯ÙˆØ± Ù€   Ù€ Ù…Ù‚Ø§Ø¨Ú©Ù„ Ù€   Ù€ ØºÙ„Ù… Ù€  " Ø¨ÙˆØ¯ .
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  Ø´Ù„Ø§Ù… ØªØ§Ø±ÛŒÚ©ÛŒØŒ Ø¯ÙˆØ³ØªÙ‡ Ù‚Ø¯ÛŒÙ…ÛŒ Ù…Ù†
[Detected]:   Ù€ Ø´Ù„Ø§Ù… Ù€  ØªØ§Ø±ÛŒÚ©ÛŒØŒ  Ù€ Ø¯ÙˆØ³ØªÙ‡ Ù€  Ù‚Ø¯ÛŒÙ…ÛŒ Ù…Ù†
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  Ø¯Ø± Ø³Ø¯Ø§ÛŒ Ø³Ú©ÙˆØªØŒ Ø¯Ø± Ø±ÙˆØ§ÛŒØ¦ Ù†Ø§Ø¢Ø±Ø§Ù… ØªÙ†Ù‡Ø§ ØºØ¯Ù… Ù…ÛŒâ€ŒØ²Ù†Ù…
[Detected]:  Ø¯Ø±  Ù€ Ø³Ø¯Ø§ÛŒ Ù€  Ø³Ú©ÙˆØªØŒ Ø¯Ø±  Ù€ Ø±ÙˆØ§ÛŒ Ù€  Ù€ Ø¦ Ù€   Ù€ Ù†Ø§Ø¢Ø±Ø§Ù… Ù€  ØªÙ†Ù‡Ø§  Ù€ ØºØ¯Ù… Ù€  Ù…ÛŒâ€ŒØ²Ù†Ù…
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  Ø²ÛŒØ± Ù‡Ù„Ù‚Ù‡ Ù†ÙˆØ± Ú†Ø±Ø§Øº Ø®ÛŒØ§Ø¨Ø§Ù†
[Detected]:  Ø²ÛŒØ±  Ù€ Ù‡Ù„Ù‚Ù‡ Ù€  Ù†ÙˆØ± Ú†Ø±Ø§Øº Ø®ÛŒØ§Ø¨Ø§Ù†
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  Ùˆ Ø¯Ø± ØµØ¯Ø§ÛŒ Ø³Ú©ÙˆØª Ø¶Ù…Ø¶Ù…Ù‡ Ù…ÛŒ Ø´ÙˆØ¯
[Detected]:  Ùˆ Ø¯Ø± ØµØ¯Ø§ÛŒ Ø³Ú©ÙˆØª  Ù€ Ø¶Ù…Ø¶Ù…Ù‡ Ù€  Ù…ÛŒ Ø´ÙˆØ¯
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  ÙˆÛŒØ±Ø§ÛŒØ³ØªÛŒØ§Ø± Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù† ØŒ Ø±ÙˆØ²Ù†Ø§Ù…Ù‡ Ù†Ú¯Ø§Ø±Ø§Ù† Ùˆ Ø§Ø³Ø­Ø§Ø¨ Ø±ØµØ§Ù†Ù‡Ù‡
[Detected]:   Ù€ ÙˆÛŒØ±Ø§ÛŒØ³ØªÛŒØ§Ø± Ù€  Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù† ØŒ Ø±ÙˆØ²Ù†Ø§Ù…Ù‡ Ù†Ú¯Ø§Ø±Ø§Ù† Ùˆ  Ù€ Ø§Ø³Ø­Ø§Ø¨ Ù€   Ù€ Ø±ØµØ§Ù†Ù‡Ù‡ Ù€ 
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  Ø¬Ú©ÛŒÙ… Ø§Ø¨ÙˆØ§Ù„Ù‚ÙØ§Ø³Ù… ÙØ±Ø°Ø¯ÙˆØ³ÛŒ Ø³Ø§Ø¹Ø± Ø­Ù…Ø§ØµÛŒ Ø³ØµØ±Ø§ÛŒ ØºØ±Ù† Ø¬Ù‡Ø§Ø±Ù… Ø§Ø³ØªØª ( ØªÙ…Ø§Ù…Ù…Ø§ Ù‚Ù„Ø· )
[Detected]:   Ù€ Ø¬Ú©ÛŒÙ… Ù€   Ù€ Ø§Ø¨ÙˆØ§Ù„Ù‚ÙØ§Ø³Ù… Ù€   Ù€ ÙØ±Ø°Ø¯ÙˆØ³ÛŒ Ù€   Ù€ Ø³Ø§Ø¹Ø± Ù€   Ù€ Ø­Ù…Ø§ØµÛŒ Ù€   Ù€ Ø³ØµØ±Ø§ÛŒ Ù€   Ù€ ØºØ±Ù† Ù€   Ù€ Ø¬Ù‡Ø§Ø±Ù… Ù€   Ù€ Ø§Ø³ØªØª Ù€  (  Ù€ ØªÙ…Ø§Ù…Ù…Ø§ Ù€   Ù€ Ù‚Ù„Ø· Ù€  )
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  Ù…ÛŒØ§Ù† Ø¹Ø§Ø´Ù‚ Ùˆ Ù…Ø¹Ø´ÙˆÙ‚ Ù‡ÛŒÚ† Ù‡Ø§Ø¦Ù„ Ù†ÛŒØ³Øª
[Detected]:  Ù…ÛŒØ§Ù† Ø¹Ø§Ø´Ù‚ Ùˆ Ù…Ø¹Ø´ÙˆÙ‚ Ù‡ÛŒÚ†  Ù€ Ù‡Ø§ Ù€  Ù€ Ø¦ Ù€  Ù€ Ù„ Ù€  Ù†ÛŒØ³Øª
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  Ø¹Ø°Ø§Ù‡Ø§ÛŒ Ø²ÙˆØ¯ Ø­Ø²Ù… Ø¨Ø±Ø§ÛŒ Ù…Ø¹Ø¯Ù‡ Ø¨Ù‡ØªØ± Ø§Ø³Øª .
[Detected]:   Ù€ Ø¹Ø°Ø§Ù‡Ø§ÛŒ Ù€  Ø²ÙˆØ¯  Ù€ Ø­Ø²Ù… Ù€  Ø¨Ø±Ø§ÛŒ Ù…Ø¹Ø¯Ù‡ Ø¨Ù‡ØªØ± Ø§Ø³Øª .
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  ØºØ¶Ø§ Ø®ÙˆØ±Ø¯Ù… Ùˆ Ø±ÙØªÙ… .
[Detected]:   Ù€ ØºØ¶Ø§ Ù€  Ø®ÙˆØ±Ø¯Ù… Ùˆ Ø±ÙØªÙ… .
----------------------------------------------------------------------------------------------------------------------------------
   [Input]:  Ø§Ùˆ Ø´Ø§Ú¯Ø±Ø¯ Ø®Ø§Øµ Ùˆ Ø¹Ù‚Ø±Ø¨ Ø¨Ù‡ Ø§Ø³ØªØ§Ø¯ Ø¨ÙˆØ¯ .
[Detected]:  Ø§Ùˆ Ø´Ø§Ú¯Ø±Ø¯ Ø®Ø§Øµ Ùˆ  Ù€ Ø¹Ù‚Ø±Ø¨ Ù€  Ø¨Ù‡ Ø§Ø³ØªØ§Ø¯ Ø¨ÙˆØ¯ .
----------------------------------------------------------------------------------------------------------------------------------
```
